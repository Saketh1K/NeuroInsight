{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:48:04.950201Z",
     "iopub.status.busy": "2024-09-29T06:48:04.949881Z",
     "iopub.status.idle": "2024-09-29T06:48:13.562293Z",
     "shell.execute_reply": "2024-09-29T06:48:13.561451Z",
     "shell.execute_reply.started": "2024-09-29T06:48:04.950167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integer labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing images from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:48:13.563980Z",
     "iopub.status.busy": "2024-09-29T06:48:13.563459Z",
     "iopub.status.idle": "2024-09-29T06:48:13.569137Z",
     "shell.execute_reply": "2024-09-29T06:48:13.568197Z",
     "shell.execute_reply.started": "2024-09-29T06:48:13.563945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_dir = r\"D:\\NeuroCure-main\\NeuroCure-main\\dataset\" # Base path to data directory\n",
    "categories = ['no_tumor', 'glioma_tumor', 'meningioma_tumor', 'pituitary_tumor'] # categories\n",
    "label_map = {\n",
    "    'no_tumor': 0,\n",
    "    'glioma_tumor': 1,\n",
    "    'meningioma_tumor': 2,\n",
    "    'pituitary_tumor': 3\n",
    "}# dictionary for category and corresponding integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:48:13.570991Z",
     "iopub.status.busy": "2024-09-29T06:48:13.570270Z",
     "iopub.status.idle": "2024-09-29T06:48:14.464508Z",
     "shell.execute_reply": "2024-09-29T06:48:14.463445Z",
     "shell.execute_reply.started": "2024-09-29T06:48:13.570933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_images(base_dir,label_map):\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    for category in categories:\n",
    "        category_path=os.path.join(base_dir,category)\n",
    "        label=label_map[category]\n",
    "\n",
    "        # listing every file in perticular directory\n",
    "        for filename in os.listdir(category_path):\n",
    "            # check file extension\n",
    "            if (filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\")):\n",
    "                image_path = os.path.join(category_path,filename)\n",
    "                images.append(image_path)\n",
    "                labels.append(label)\n",
    "    return images,labels\n",
    "        \n",
    "images,labels=load_images(base_dir,label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine shuffle and seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:48:14.468712Z",
     "iopub.status.busy": "2024-09-29T06:48:14.468069Z",
     "iopub.status.idle": "2024-09-29T06:48:14.669050Z",
     "shell.execute_reply": "2024-09-29T06:48:14.667951Z",
     "shell.execute_reply.started": "2024-09-29T06:48:14.468673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\NeuroCure-main\\NeuroCure-main\\dataset\\pituitary_tumor\\Tr-pi_0868.jpg\n"
     ]
    }
   ],
   "source": [
    "combined = list(zip(images, labels))\n",
    "np.random.shuffle(combined)\n",
    "images, labels = zip(*combined)\n",
    "print(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into train,validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:48:14.670823Z",
     "iopub.status.busy": "2024-09-29T06:48:14.670430Z",
     "iopub.status.idle": "2024-09-29T06:48:14.722855Z",
     "shell.execute_reply": "2024-09-29T06:48:14.721909Z",
     "shell.execute_reply.started": "2024-09-29T06:48:14.670768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 70% train, 30% temp\n",
    "train_imgs, temp_imgs, train_labels, temp_labels = train_test_split(images, labels, test_size=0.3, stratify=labels)\n",
    "\n",
    "# 50% of temp in each test and val\n",
    "val_imgs, test_imgs, val_labels, test_labels = train_test_split(temp_imgs, temp_labels, test_size=0.5,stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding and Preprocessing images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:48:14.724911Z",
     "iopub.status.busy": "2024-09-29T06:48:14.724236Z",
     "iopub.status.idle": "2024-09-29T06:48:15.502891Z",
     "shell.execute_reply": "2024-09-29T06:48:15.501821Z",
     "shell.execute_reply.started": "2024-09-29T06:48:14.724866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new=tf.io.read_file(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:48:15.504682Z",
     "iopub.status.busy": "2024-09-29T06:48:15.504315Z",
     "iopub.status.idle": "2024-09-29T06:48:15.513443Z",
     "shell.execute_reply": "2024-09-29T06:48:15.512512Z",
     "shell.execute_reply.started": "2024-09-29T06:48:15.504646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new1=tf.io.decode_image(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:48:15.514994Z",
     "iopub.status.busy": "2024-09-29T06:48:15.514695Z",
     "iopub.status.idle": "2024-09-29T06:48:15.524113Z",
     "shell.execute_reply": "2024-09-29T06:48:15.523138Z",
     "shell.execute_reply.started": "2024-09-29T06:48:15.514962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512, 512, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:48:15.555134Z",
     "iopub.status.busy": "2024-09-29T06:48:15.554695Z",
     "iopub.status.idle": "2024-09-29T06:50:59.535739Z",
     "shell.execute_reply": "2024-09-29T06:50:59.534681Z",
     "shell.execute_reply.started": "2024-09-29T06:48:15.555095Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4131, 224, 224, 3)\n",
      "(4131,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_images(image_paths, labels, batch_size=32):\n",
    "    num_images = len(image_paths)\n",
    "    processed_images = []\n",
    "    processed_labels = []\n",
    "\n",
    "    for start in range(0, num_images, batch_size):\n",
    "        end = min(start + batch_size, num_images)\n",
    "\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for img_path, label in zip(image_paths[start:end], labels[start:end]):\n",
    "            # Open the image using Pillow\n",
    "            image = Image.open(img_path).convert('RGB')  # Convert to RGB\n",
    "            \n",
    "            # Resize the image to 224x224\n",
    "            image = image.resize((224, 224))\n",
    "            \n",
    "            # Convert the image to a numpy array\n",
    "            image_array = np.array(image)\n",
    "            \n",
    "            # Normalize the image to the range [0, 1]\n",
    "            image_array = image_array / 255.0\n",
    "            \n",
    "            # Add image array to the batch list\n",
    "            batch_images.append(image_array)\n",
    "            \n",
    "            # Add label to the batch labels list\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        # Convert batch lists to numpy arrays\n",
    "        processed_images.append(np.array(batch_images, dtype=np.float32))\n",
    "        processed_labels.append(np.array(batch_labels, dtype=np.int64))\n",
    "\n",
    "    # Concatenate all processed batches into final arrays\n",
    "    processed_images = np.concatenate(processed_images, axis=0)\n",
    "    processed_labels = np.concatenate(processed_labels, axis=0)\n",
    "\n",
    "    return processed_images, processed_labels\n",
    "\n",
    "# Assuming train_imgs and train_labels are defined\n",
    "train_images, train_labels = preprocess_images(train_imgs[:10000], train_labels[:10000], batch_size=2)\n",
    "val_images, val_labels = preprocess_images(val_imgs[:10000], val_labels[:10000], batch_size=2)\n",
    "\n",
    "print(train_images.shape)  # Should print something like (num_images, 224, 224, 3)\n",
    "print(train_labels.shape)  # Should print (num_images,)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:50:59.546823Z",
     "iopub.status.busy": "2024-09-29T06:50:59.546526Z",
     "iopub.status.idle": "2024-09-29T06:50:59.578313Z",
     "shell.execute_reply": "2024-09-29T06:50:59.577564Z",
     "shell.execute_reply.started": "2024-09-29T06:50:59.546790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.layers import Dense , GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:50:59.579760Z",
     "iopub.status.busy": "2024-09-29T06:50:59.579394Z",
     "iopub.status.idle": "2024-09-29T06:50:59.585421Z",
     "shell.execute_reply": "2024-09-29T06:50:59.584052Z",
     "shell.execute_reply.started": "2024-09-29T06:50:59.579715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:50:59.595246Z",
     "iopub.status.busy": "2024-09-29T06:50:59.594775Z",
     "iopub.status.idle": "2024-09-29T06:53:16.682702Z",
     "shell.execute_reply": "2024-09-29T06:53:16.681751Z",
     "shell.execute_reply.started": "2024-09-29T06:50:59.595183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 353ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_10\" is incompatible with the layer: expected axis -1 of input shape to have value 36992, but received input with shape (8, 86528)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(8, 224, 224, 3), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 34\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#     for batch_images, batch_labels in train_data.take(1):\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#         print(\"Image batch shape:\", batch_images.shape)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#         print(\"Label batch shape:\", batch_labels.shape)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#         break\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#     print(train_images.shape)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Assume X_val is your validation data\u001b[39;00m\n\u001b[0;32m     33\u001b[0m resnet_preds \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mpredict(train_images,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)  \u001b[38;5;66;03m# ResNet model predictions\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m custom_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Custom model predictions\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Assume X_val is your validation data\u001b[39;00m\n\u001b[0;32m     37\u001b[0m resnet_preds_val \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mpredict(val_images, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)  \u001b[38;5;66;03m# ResNet model predictions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saket\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\saket\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_10\" is incompatible with the layer: expected axis -1 of input shape to have value 36992, but received input with shape (8, 86528)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(8, 224, 224, 3), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense,Dropout\n",
    "from tensorflow.keras.layers import Dense,Dropout, MaxPooling2D, Conv2D,BatchNormalization, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Detect and initialize the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect the TPU hardware\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)  # Initialize the TPU system\n",
    "\n",
    "# # Instantiate the TPU distribution strategy\n",
    "# tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
    "\n",
    "# #Define the model within the TPU strategy scope\n",
    "# with tpu_strategy.scope():\n",
    "        # Assuming you have a pre-trained base model (like MobileNet, EfficientNet, etc.)\n",
    "\n",
    "# Loading both models\n",
    "model_1=load_model(\"D://NeuroCure-main//NeuroCure-main//notebooks//ResNet50V2.keras\")\n",
    "model_2=load_model(\"D://NeuroCure-main//NeuroCure-main//notebooks//custom_model.keras\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     for batch_images, batch_labels in train_data.take(1):\n",
    "#         print(\"Image batch shape:\", batch_images.shape)\n",
    "#         print(\"Label batch shape:\", batch_labels.shape)\n",
    "#         break\n",
    "#     print(train_images.shape)\n",
    "# Assume X_val is your validation data\n",
    "resnet_preds = model_1.predict(train_images,batch_size=8)  # ResNet model predictions\n",
    "custom_preds = model_2.predict(train_images,batch_size=8)  # Custom model predictions\n",
    "\n",
    "# Assume X_val is your validation data\n",
    "resnet_preds_val = model_1.predict(val_images, batch_size=8)  # ResNet model predictions\n",
    "custom_preds_val = model_2.predict(val_images, batch_size=8)  # Custom model predictions\n",
    "\n",
    "# Stack predictions side by side\n",
    "print(resnet_preds.shape)\n",
    "print(custom_preds.shape)\n",
    "\n",
    "combined_preds = np.column_stack((resnet_preds, custom_preds))\n",
    "# Stack predictions side by side\n",
    "combined_preds_val = np.column_stack((resnet_preds_val, custom_preds_val))\n",
    "\n",
    "\n",
    "# Build a meta-model (simple fully connected network)\n",
    "meta_model = Sequential([\n",
    "Dense(128, activation='relu', input_shape=(combined_preds.shape[1],)),\n",
    "Dense(64, activation='relu'),\n",
    "Dense(4, activation='softmax')  # Assuming binary classification (adjust for multi-class)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "optimizer=Adam(learning_rate=0.001)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "monitor='val_loss',\n",
    "patience=3,  # Stop if no improvement for 3 epochs\n",
    "verbose=1,\n",
    "restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "'meta_model.keras',\n",
    "monitor='val_loss',\n",
    "save_best_only=True,\n",
    "verbose=1\n",
    ")\n",
    "\n",
    "# Compile the model with optimizer, loss function, and metrics\n",
    "meta_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model normally\n",
    "meta_model.fit(combined_preds,train_labels,\n",
    "          epochs=30, \n",
    "           validation_data=(combined_preds_val,val_labels),\n",
    "           callbacks=[early_stopping,model_checkpoint]\n",
    "#           steps_per_epoch=1500\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:53:16.684257Z",
     "iopub.status.busy": "2024-09-29T06:53:16.683921Z",
     "iopub.status.idle": "2024-09-29T06:53:16.688608Z",
     "shell.execute_reply": "2024-09-29T06:53:16.687543Z",
     "shell.execute_reply.started": "2024-09-29T06:53:16.684207Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmeta_model\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'meta_model' is not defined"
     ]
    }
   ],
   "source": [
    "meta_model.save(\"meta_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:53:16.690339Z",
     "iopub.status.busy": "2024-09-29T06:53:16.689952Z",
     "iopub.status.idle": "2024-09-29T06:53:16.698215Z",
     "shell.execute_reply": "2024-09-29T06:53:16.697300Z",
     "shell.execute_reply.started": "2024-09-29T06:53:16.690282Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmeta_model\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'meta_model' is not defined"
     ]
    }
   ],
   "source": [
    "meta_model.evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5721479,
     "sourceId": 9420055,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 127772,
     "modelInstanceId": 103552,
     "sourceId": 123036,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 127810,
     "modelInstanceId": 103588,
     "sourceId": 123075,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
